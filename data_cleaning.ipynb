{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path, output_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    with open(output_path, 'w', encoding='utf-8') as f_out:\n",
    "        f_out.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdf_path = 'Sahih_Al-Bukhari.pdf'\n",
    "output_path = 'Sahih_Bukhari_extracted.txt'\n",
    "\n",
    "extract_text_from_pdf(pdf_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'Sahih_Muslim.pdf'\n",
    "output_path = 'Sahih_Muslim_extracted.txt'\n",
    "\n",
    "extract_text_from_pdf(pdf_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning Al-Bukhari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bukhari = open('Sahih_Bukhari_extracted.txt')#.read()\n",
    "hadees_no = {}\n",
    "\n",
    "for i in bukhari:\n",
    "    # print(i.rstrip())\n",
    "    if 'Number' in i:\n",
    "        hadees_no[i.strip()] = None\n",
    "        # print(i)\n",
    "    \n",
    "# corpus = \"\"\n",
    "# for line in bukhari:\n",
    "#     corpus = \"\".join([corpus,line.strip()])\n",
    "    # print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bukhari = open('Sahih_Bukhari_extracted.txt', 'r', encoding='utf-8')  # Ensure you provide the correct path\n",
    "\n",
    "hadees_no = {}\n",
    "capture_text = False\n",
    "current_hadith = None\n",
    "text_buffer = []\n",
    "n1,n2 = 1,2\n",
    "for line in bukhari:\n",
    "    line = line.strip()\n",
    "    if f'Number {n1}' in line:  # Detecting the start of a new Hadith\n",
    "        if current_hadith is not None:  # Not the first Hadith; previous one's text capture is complete\n",
    "            hadees_no[current_hadith] = '\\n'.join(text_buffer)\n",
    "            text_buffer = []  # Reset buffer for the next Hadith\n",
    "            if f'Number {n2}' in line:  # If we've reached Hadith Number 2, stop capturing and break\n",
    "                break\n",
    "        current_hadith = line  # Update the current Hadith marker\n",
    "        capture_text = True  # Start capturing text for the new Hadith\n",
    "        n1+=1\n",
    "        n2+=1\n",
    "    elif capture_text:\n",
    "        text_buffer.append(line.strip())  # Capture the line of text within a Hadith\n",
    "    \n",
    "# Don't forget to add the last captured Hadith if the loop ends before reaching the next marker\n",
    "if text_buffer and current_hadith is not None:\n",
    "    hadees_no[current_hadith] = '\\n'.join(text_buffer)\n",
    "\n",
    "bukhari.close()  # Always close the file when done\n",
    "\n",
    "# Print the captured text for verification\n",
    "for hadith, text in hadees_no.items():\n",
    "    print(f\"{hadith}:\\n{text}\\n\\n---\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_key(key):\n",
    "    # Standardize the Hadith reference format\n",
    "    parts = key.split(',')\n",
    "    cleaned_parts = [part.strip() for part in parts]\n",
    "    return ' '.join(cleaned_parts)\n",
    "\n",
    "def clean_value(value):\n",
    "    # Clean the Hadith text\n",
    "    cleaned_text = ' '.join(value.strip().split())\n",
    "    return cleaned_text\n",
    "\n",
    "cleaned_hadees_no = {clean_key(key): clean_value(value) for key, value in hadees_no.items()}\n",
    "\n",
    "# Display the cleaned keys and values for verification\n",
    "for key, value in cleaned_hadees_no.items():\n",
    "    print(f\"{key}: {value}\\n\\n---\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "structured_hadees_df = pd.DataFrame(cleaned_hadees_no,index=['Hadees']).T\n",
    "# \n",
    "structured_hadees_df.index.name = 'Volume'\n",
    "structured_hadees_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_hadees_text(text):\n",
    "    # Remove Volume and Book references\n",
    "    cleaned_text = re.sub(r'Volume \\d+ - \\d+ / \\d+ SAHIH BUKHARI VOLUME \\d+ > BOOK \\d+: [A-Z ]+', '', text)\n",
    "    \n",
    "    # Remove parentheses and their contents\n",
    "    cleaned_text = re.sub(r'\\(.*?\\)', '', cleaned_text)\n",
    "    # Optionally, remove brackets and their contents if present\n",
    "    # cleaned_text = re.sub(r'\\[.*?\\]', '', cleaned_text)\n",
    "    \n",
    "    # Remove new lines and excessive whitespace\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "    \n",
    "    # Remove special characters if needed (keeping apostrophes)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s\\']', '', cleaned_text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "cleaned_hadees = structured_hadees_df.copy()\n",
    "cleaned_hadees['Hadees'] = cleaned_hadees['Hadees'].apply(clean_hadees_text)   \n",
    "\n",
    "cleaned_hadees['Hadees'] = cleaned_hadees['Hadees'].str.replace('Abii','Abu')\n",
    "cleaned_hadees.to_csv('Cleaned1_Shahi_bukhari.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "string = []\n",
    "values = cleaned_hadees.loc['Volume 1 Book 1 Number 5:'].values[0].split()\n",
    "for count in range(len(values)):\n",
    "    if count+1>=len(values):break\n",
    "    w1 = values[count]\n",
    "    w2 = values[count+1]\n",
    "    word = \"\".join([w1,w2])\n",
    "    correct = str(TextBlob(word).correct())\n",
    "    if word == correct:\n",
    "        string.append(correct)\n",
    "    else:\n",
    "        string.append(values[count]+'e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "values = cleaned_hadees.loc['Volume 1 Book 1 Number 5:'].values[0].split()\n",
    "output = []\n",
    "last_added = None\n",
    "\n",
    "for i in range(len(values)):\n",
    "    # Handle the last word case\n",
    "    if i + 1 >= len(values):\n",
    "        if last_added != values[i]:\n",
    "            output.append(values[i])\n",
    "        break\n",
    "    \n",
    "    w1, w2 = values[i], values[i+1]\n",
    "    combined_correction = str(TextBlob(w1 + \" \" + w2).correct())\n",
    "    \n",
    "    # If the combined correction is different, decide based on whether w1 is correct\n",
    "    if (w1 + \" \" + w2) != combined_correction:\n",
    "        w1_corrected = str(TextBlob(w1).correct())\n",
    "        if w1 == w1_corrected:  # If w1 is correct, add it once and handle w2 in next iteration\n",
    "            if last_added != w1:\n",
    "                output.append(w1)\n",
    "                last_added = w1\n",
    "        else:\n",
    "            # If w1 needs correction or combined words form a correction, add combined\n",
    "            output.append(combined_correction)\n",
    "            last_added = w2  # Assume w2 is part of the correction\n",
    "    else:\n",
    "        # If no correction needed, add w1 if it wasn't added last\n",
    "        if last_added != w1:\n",
    "            output.append(w1)\n",
    "            last_added = w1\n",
    "\n",
    "# Join the output list to form the corrected string\n",
    "corrected_string = \" \".join(output)\n",
    "print(corrected_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrators = []\n",
    "\n",
    "for narrator in cleaned_hadees_no.values():\n",
    "    v = \" \".join(narrator.split(':')[0].split()[1:]) + \" RA\"\n",
    "    v = \"_\".join(v.split())\n",
    "    v_cleaned = v.replace(\"'\", \"\")  # Replace '#' with any specific symbol you need to remove\n",
    "    narrators.append(v_cleaned)\n",
    "    # print(v_cleaned)\n",
    "    \n",
    "print('Total Narrators: ',len(set(narrators)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrator_count_df = pd.Series(narrators,name='narrator').value_counts().to_frame()#.head(20)\n",
    "total_hadiths = len(cleaned_hadees_no)  # Total number of hadiths as the denominator for the ratio\n",
    "\n",
    "# Calculate the ratio of occurrences of each narrator to the total number of Hadith\n",
    "narrator_count_df['Ratio'] = (narrator_count_df['count'] / total_hadiths)*100\n",
    "\n",
    "narrator_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(hadees):\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(api_key=\"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\")\n",
    "    # client.api_key = \"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\"\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"text cleaning agent where you are going to be given single hadees from sahih hadees and you are supposed to correct spell mistakes\"},\n",
    "        {\"role\": \"user\", \"content\": hadees,}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    corrected_text = response.choices[0].text.strip()  # Adjust this according to the actual structure of OpenAI's response\n",
    "\n",
    "    return corrected_text\n",
    "\n",
    "cleaned_hadees['Hadees'].apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "narrator_frequencies = narrator_count_df['count'].to_dict()\n",
    "\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(narrator_frequencies)\n",
    "\n",
    "plt.figure(figsize=(10, 5),dpi=1200)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('narrators.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "top_narrators = narrator_count_df['Ratio'].head(20)  # Use 'Ratio' instead of 'Count' for this visualization\n",
    "colors = plt.cm.Greens_r(np.linspace(0, 1, len(top_narrators)))\n",
    "\n",
    "ax = top_narrators.plot(kind='bar', figsize=(14, 7),color=colors, edgecolor='black')\n",
    "\n",
    "plt.title('Top 20 Narrators by Ratio', fontsize=20)\n",
    "plt.xlabel('Narrator', fontsize=14)\n",
    "plt.ylabel('Ratio (%)', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', linewidth=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Annotating each bar with the ratio value\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height():.2f}%\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', fontsize=10, color='black', rotation=0, xytext=(0, 10),\n",
    "                textcoords='offset points')\n",
    "\n",
    "plt.savefig('top_narrator_ratio.png', bbox_inches='tight')  # Save the figure as a .png file\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
